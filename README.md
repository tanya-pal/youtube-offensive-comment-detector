YouTube Offensive Comment Moderation System

ðŸ”¹ Input Dataset:
â€¢	I used a shortened version of Kaggle's Jigsaw Toxic Comment Classification Challenge, trimmed to 500 rows and saved as youtube_offensive_dataset.csv.
ðŸ”¹ Models Built:
â€¢	Binary Classifier (offensive column): Detects whether a comment is offensive or not.
â€¢	Multi-label Classifier (type column): Predicts offensive categories (if any).
â€¢	Both models are trained with TfidfVectorizer + RandomForestClassifier.
â€¢	Saved to:
ïƒ˜	binary_offensive_model.pkl
ïƒ˜	type_classification_model.pkl
ïƒ˜	label_binarizer.pkl
ðŸ”¹ YouTube API Integration:
â€¢	Credentials stored in client_secret.json.
â€¢	Uses OAuth 2.0 authentication.
â€¢	Scans your channelâ€™s videos, fetches comments, checks for offensiveness, and automatically deletes the offensive ones.
ðŸ”¹ Moderation Logic (youtube_cleanup.py):
â€¢	Gets videos from a channel using channel_id .
â€¢	Fetches all comments.
â€¢	If a comment is offensive:
o	Deletes it.
o	Saves it to deleted_comments.csv
o	Tracks offense counts per user into offensive_user_counts.csv
â€¢	Polls every 5 minutes.

